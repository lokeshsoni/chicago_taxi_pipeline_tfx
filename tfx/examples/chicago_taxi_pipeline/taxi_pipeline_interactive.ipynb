{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "taxi_pipeline_interactive.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ZcUHhxHei1oJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R0Z9RojXYW",
        "colab_type": "text"
      },
      "source": [
        "# TFX Iterative Development Example\n",
        "This notebook demonstrates how to use Jupyter notebooks for TFX iterative development.  Here, we walk through the Chicago Taxi example in an interactive Jupyter notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GivNBNYjb3b",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "First, we install the necessary packages, download data, import modules and set up paths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNMMAVwGj2Sl",
        "colab_type": "text"
      },
      "source": [
        "### Install TFX and Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gg04ijlfJRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install http://tfx-ccy-public.storage.googleapis.com/tfx-0.14.0.dev0-py3-none-any.whl tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ePgV0Lj68Q",
        "colab_type": "text"
      },
      "source": [
        "### Import packages\n",
        "We import necessary packages, including standard TFX component classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIqpWK9efviJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import tfx\n",
        "from tfx.components.evaluator.component import Evaluator\n",
        "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
        "from tfx.components.example_validator.component import ExampleValidator\n",
        "from tfx.components.model_validator.component import ModelValidator\n",
        "from tfx.components.pusher.component import Pusher\n",
        "from tfx.components.schema_gen.component import SchemaGen\n",
        "from tfx.components.statistics_gen.component import StatisticsGen\n",
        "from tfx.components.trainer.component import Trainer\n",
        "from tfx.components.transform.component import Transform\n",
        "from tfx.orchestration.interactive.interactive_context import InteractiveContext\n",
        "from tfx.proto import evaluator_pb2\n",
        "from tfx.proto import pusher_pb2\n",
        "from tfx.proto import trainer_pb2\n",
        "from tfx.proto.evaluator_pb2 import SingleSlicingSpec\n",
        "from tfx.utils.dsl_utils import csv_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcUHhxHei1oJ",
        "colab_type": "text"
      },
      "source": [
        "### (in progress: inject IPython formatter integration)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rY34WxkijBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TFX IPython formatter integration\n",
        "# TODO: integrate this\n",
        "from tfx.orchestration.interactive.interactive_context import ExecutionResult\n",
        "\n",
        "def style():\n",
        "    return '''<style>\n",
        ".object {\n",
        "}\n",
        ".object.expanded {\n",
        "padding: 4px 8px 4px 8px;\n",
        "border: 1px solid #bbbbbb;\n",
        "box-shadow: 4px 4px 2px rgba(0,0,0,0.05);\n",
        "background: white;\n",
        "border-radius: 0;\n",
        "}\n",
        ".object, .object * {\n",
        "font-size: 11pt;\n",
        "}\n",
        ".object > .title {\n",
        "cursor: pointer;\n",
        "}\n",
        ".expansion-marker {\n",
        "color: #999999;\n",
        "}\n",
        ".object.expanded > .title > .expansion-marker:before {\n",
        "content: '▼'\n",
        "}\n",
        ".object.collapsed > .title > .expansion-marker:before {\n",
        "content: '▶'\n",
        "}\n",
        ".classname {\n",
        "font-weight: bold\n",
        "}\n",
        ".deemph {\n",
        "opacity: 0.5;\n",
        "}\n",
        ".object.collapsed > table.attrtable {\n",
        "display: none;\n",
        "}\n",
        ".object.expanded > table.attrtable {\n",
        "display: block;\n",
        "}\n",
        "table.attrtable {\n",
        "border: 2px solid white;\n",
        "margin-top: 5px;\n",
        "}\n",
        "table.attrtable tr {\n",
        "}\n",
        "td.attrname {\n",
        "vertical-align: top;\n",
        "font-weight: bold;\n",
        "}\n",
        "td.attrvalue {\n",
        "text-align: left\n",
        "}\n",
        "</style>\n",
        "<script>\n",
        "function toggle(element) {\n",
        "var obj_element = element.parentElement;\n",
        "if (obj_element.classList.contains('collapsed')) {\n",
        "obj_element.classList.remove('collapsed');\n",
        "obj_element.classList.add('expanded');\n",
        "} else {\n",
        "obj_element.classList.add('collapsed');\n",
        "obj_element.classList.remove('expanded');\n",
        "}\n",
        "}\n",
        "</script>\n",
        "'''\n",
        "\n",
        "def execution_result(obj):\n",
        "    return style() + '''''' % (obj.__class__.__name__, id(obj), obj.execution_id, obj.component.component_name, obj.component.inputs) + repr(obj)\n",
        "\n",
        "from typing import Text, Type\n",
        "\n",
        "from tfx.components.base.base_component import _PropertyDictWrapper\n",
        "from tfx.utils.channel import Channel\n",
        "from tfx.utils.types import TfxArtifact\n",
        "\n",
        "class NotebookFormatter(object):\n",
        "    _DEFAULT_TITLE_FORMAT = ('<span class=\"classname\">%s</span>', ['__class__.__name__'])\n",
        "    \n",
        "    def __init__(self, cls: Type, expandable: bool=False, attributes=None, title_format=None):\n",
        "        self.cls = cls\n",
        "        self.expandable = expandable\n",
        "        self.attributes = attributes or []\n",
        "        self.title_format = title_format or NotebookFormatter._DEFAULT_TITLE_FORMAT\n",
        "\n",
        "    def _extended_getattr(self, obj, property_name: Text):\n",
        "        # print('_extended_getattr', obj.__class__, property_name)\n",
        "        if callable(property_name):\n",
        "            return property_name(obj)\n",
        "        parts = property_name.split('.')\n",
        "        current = obj\n",
        "        for part in parts:\n",
        "            current = getattr(current, part)\n",
        "        return current\n",
        "    \n",
        "    def render(self, obj: object, expanded=True, seen_elements=None):\n",
        "        seen_elements = seen_elements or set()\n",
        "        if id(obj) in seen_elements:\n",
        "            return '(recursion in rendering object)'\n",
        "        seen_elements.add(id(obj))\n",
        "        if not isinstance(obj, self.cls):\n",
        "            raise ValueError('Expected object of type %s but got %s.' % (self.cls, obj))\n",
        "        seen_elements.remove(id(obj))\n",
        "        return style() + '''<div class=\"object%s\">\n",
        "<div class = 'title' onclick='toggle(this)'><span class=\"expansion-marker\"></span>\n",
        "%s<span class=\"deemph\"> at 0x%x</span></div>%s\n",
        "</div>''' % (' expanded' if expanded else ' collapsed', self.render_title(obj), id(obj),\n",
        "             self.render_attributes(obj, seen_elements))\n",
        "    \n",
        "    def render_title(self, obj: object):\n",
        "        title_format = self.title_format\n",
        "        values = []\n",
        "        for property_name in title_format[1]:\n",
        "            values.append(self._extended_getattr(obj, property_name))\n",
        "        return title_format[0] % tuple(values)\n",
        "    \n",
        "    def render_value(self, value: object, seen_elements: set):\n",
        "        if isinstance(value, _PropertyDictWrapper):\n",
        "            value = value.get_all()\n",
        "        if isinstance(value, dict):\n",
        "            value = self.render_dict(value, seen_elements)\n",
        "        if isinstance(value, list):\n",
        "            value = self.render_list(value, seen_elements)\n",
        "        for cls in value.__class__.mro():\n",
        "            # print(value.__class__, cls)\n",
        "            if cls in FORMATTER_REGISTRY:\n",
        "                value = FORMATTER_REGISTRY[cls].render(value, expanded=False, seen_elements=seen_elements)\n",
        "                break\n",
        "        return value\n",
        "    \n",
        "    def render_attributes(self, obj: object, seen_elements: set):\n",
        "        attr_trs = []\n",
        "        for property_name in self.attributes:\n",
        "            value = self._extended_getattr(obj, property_name)\n",
        "            value = self.render_value(value, seen_elements)\n",
        "            attr_trs.append('''<tr><td class=\"attrname\">.%s</td>\n",
        "<td class = \"attrvalue\">%s</td></tr>''' % (property_name, value))\n",
        "        return '''<table class=\"attrtable\">%s</table>''' % ''.join(attr_trs)\n",
        "    \n",
        "    def render_dict(self, obj: dict, seen_elements: set):\n",
        "        if not obj:\n",
        "            return '{}'\n",
        "        attr_trs = []\n",
        "        for key, value in obj.items():\n",
        "            value = self.render_value(value, seen_elements)\n",
        "            attr_trs.append('''<tr><td class=\"attrname\">[%r]</td>\n",
        "<td class = \"attrvalue\">%s</td></tr>''' % (key, value))\n",
        "        return '''<table class=\"attrtable\">%s</table>''' % ''.join(attr_trs)\n",
        "    \n",
        "    def render_list(self, obj: dict, seen_elements: set):\n",
        "        if not obj:\n",
        "            return '[]'\n",
        "        attr_trs = []\n",
        "        for i, value in enumerate(obj):\n",
        "            value = self.render_value(value, seen_elements)\n",
        "            attr_trs.append('''<tr><td class=\"attrname\">[%d]</td>\n",
        "<td class = \"attrvalue\">%s</td></tr>''' % (i, value))\n",
        "        return '''<table class=\"attrtable\">%s</table>''' % ''.join(attr_trs)\n",
        "        \n",
        "        \n",
        "def create_formatters(formatters_spec):\n",
        "    result = {}\n",
        "    for cls, kwargs in formatters_spec.items():\n",
        "        formatter = NotebookFormatter(cls, **kwargs)\n",
        "        result[cls] = formatter\n",
        "    return result\n",
        "\n",
        "from tfx.components.base.base_component import BaseComponent\n",
        "from tfx.utils.channel import Channel\n",
        "from tfx.utils.types import TfxArtifact\n",
        "\n",
        "FORMATTER_REGISTRY = create_formatters({\n",
        "    ExecutionResult: {'attributes': ['execution_id', 'component', 'component.inputs', 'component.outputs']},\n",
        "    BaseComponent: {'attributes': ['inputs', 'outputs', 'exec_properties']},\n",
        "    Channel: {'attributes': ['type_name', '_artifacts'],\n",
        "                 'title_format': ('<span class=\"classname\">%s</span> of type <span class=\"classname\">%r</span> (%d artifact%s)',\n",
        "                                  ['__class__.__name__', 'type_name', lambda o: len(o._artifacts), lambda o: '' if len(o._artifacts) == 1 else 's']),\n",
        "             },\n",
        "    TfxArtifact: {'attributes': ['type_name', 'uri', 'span', 'split'],\n",
        "                 'title_format': ('<span class=\"classname\">%s</span> of type <span class=\"classname\">%r</span> (uri: %s)',\n",
        "                                  ['__class__.__name__', 'type_name', 'uri']),\n",
        "                 }\n",
        "})\n",
        "\n",
        "html_formatter = get_ipython().display_formatter.formatters['text/html']\n",
        "for cls, formatter in FORMATTER_REGISTRY.items():\n",
        "    html_formatter.for_type(cls, formatter.render)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cMMAbSkGfX",
        "colab_type": "text"
      },
      "source": [
        "### Download example data\n",
        "We download the sample dataset for use in our TFX pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BywX6OUEhAqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the example data.\n",
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n",
        "with open(os.path.join(_data_root, 'data.csv'), 'wb') as f:\n",
        "  contents = urllib.request.urlopen(DATA_PATH).read()\n",
        "  f.write(contents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJKQ6OvkJlY",
        "colab_type": "text"
      },
      "source": [
        "### Set up pipeline paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad5JLpKbf6sN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up paths.\n",
        "_taxi_root = os.path.join(tfx.__path__[0], 'examples/chicago_taxi_pipeline')\n",
        "# Python module file to inject customized logic into the TFX components. The\n",
        "# Transform and Trainer both require user-defined functions to run successfully.\n",
        "_taxi_module_file = os.path.join(_taxi_root, 'taxi_utils.py')\n",
        "# Path which can be listened to by the model server.  Pusher will output the\n",
        "# trained model here.\n",
        "_serving_model_dir = os.path.join(tempfile.mkdtemp(), 'serving_model/taxi_simple')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4",
        "colab_type": "text"
      },
      "source": [
        "## Create the InteractiveContext\n",
        "We now create the interactive context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rh6K5sUf9dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext.\n",
        "context = InteractiveContext()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ",
        "colab_type": "text"
      },
      "source": [
        "## Run TFX components interactively\n",
        "Next, we construct TFX components and run each one interactively using within the interactive session to obtain `ExecutionResult` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fwt9gQk3BR",
        "colab_type": "text"
      },
      "source": [
        "### ExampleGen\n",
        "`ExampleGen` brings data into the TFX pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyXjuMt8f-9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the packaged CSV input data.\n",
        "examples = csv_input(_data_root)\n",
        "\n",
        "# Brings data into the pipeline or otherwise joins/converts training data.\n",
        "example_gen = CsvExampleGen(input_base=examples)\n",
        "context.run(example_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa",
        "colab_type": "text"
      },
      "source": [
        "### StatisticsGen (using Tensorflow Data Validation)\n",
        "`StatisticsGen` computes statistics for visualization and example validation. This uses the [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0tl75TMW3DR",
        "colab_type": "text"
      },
      "source": [
        "#### Run TFDV statistics computation using the StatisticsGen component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAscCCYWgA-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computes statistics over data for visualization and example validation.\n",
        "statistics_gen = StatisticsGen(\n",
        "    input_data=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ",
        "colab_type": "text"
      },
      "source": [
        "#### Import TFDV and visualize the statistics result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLjXy7K6Tp_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import TFDV and get the train statistics path.\n",
        "import tensorflow_data_validation as tfdv\n",
        "from tfx.utils.types import get_split_uri\n",
        "artifact_list = statistics_gen.outputs['output'].get()\n",
        "train_artifact_uri = get_split_uri(artifact_list, 'train')\n",
        "train_stats_path = os.path.join(train_artifact_uri, 'stats_tfrecord')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKicTZkPTUY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load statistics and visualize training data stats.\n",
        "train_stats = tfdv.load_statistics(train_stats_path)\n",
        "tfdv.visualize_statistics(train_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p",
        "colab_type": "text"
      },
      "source": [
        "### SchemaGen (using Tensorflow Data Validation)\n",
        "`SchemaGen` generates a schema for your data based on computed statistics. This component also uses the [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0xvulenXSK3",
        "colab_type": "text"
      },
      "source": [
        "#### Run TFDV schema inference using the SchemaGen component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQvZ6hsiQ_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates schema based on statistics files.\n",
        "infer_schema = SchemaGen(stats=statistics_gen.outputs['output'])\n",
        "context.run(infer_schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6TxTUKXM6b",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize the inferred schema\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec9vqDXpXeMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the schema path.\n",
        "schema_dir = infer_schema.outputs['output'].get()[0].uri\n",
        "schema_path = os.path.join(schema_dir, 'schema.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaaA49ArYLQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load and visualize the generated schema.\n",
        "schema = tfdv.load_schema_text(schema_path)\n",
        "tfdv.display_schema(schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8",
        "colab_type": "text"
      },
      "source": [
        "### ExampleValidator\n",
        "`ExampleValidator` performs anomaly detection based on computed statistics and your data schema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONg1bt57gVna",
        "colab_type": "text"
      },
      "source": [
        "#### Run TFDV data validation using the ExampleValidation component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRlRUuGgiXks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performs anomaly detection based on statistics and data schema.\n",
        "validate_stats = ExampleValidator(\n",
        "    stats=statistics_gen.outputs['output'],\n",
        "    schema=infer_schema.outputs['output'])\n",
        "context.run(validate_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize the detected anomalies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDyAAozQcrk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the validation path.\n",
        "validation_dir = validate_stats.outputs['output'].get()[0].uri\n",
        "anomalies_path = os.path.join(validation_dir, 'anomalies.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDhjfHFjcz1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load and visualize the anomalies.\n",
        "\n",
        "# Utility function backported from TFDV 0.14.\n",
        "def load_anomalies_text(input_path):\n",
        "  from google.protobuf import text_format\n",
        "  from tensorflow.python.lib.io import file_io\n",
        "  from tensorflow_metadata.proto.v0 import anomalies_pb2\n",
        "  anomalies = anomalies_pb2.Anomalies()\n",
        "  anomalies_text = file_io.read_file_to_string(input_path)\n",
        "  text_format.Parse(anomalies_text, anomalies)\n",
        "  return anomalies\n",
        "\n",
        "anomalies = load_anomalies_text(anomalies_path)\n",
        "# anomalies = tfdv.load_anomalies_text(anomalies_path)  # Will be available once TFDV 0.14 is released.\n",
        "tfdv.display_anomalies(anomalies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36",
        "colab_type": "text"
      },
      "source": [
        "### Transform\n",
        "`Transform` performs data transformations and feature engineering which are kept in sync for training and serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW",
        "colab_type": "text"
      },
      "source": [
        "#### Run the Transform component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfhth_GiZI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performs transformations and feature engineering in training and serving.\n",
        "transform = Transform(\n",
        "    input_data=example_gen.outputs['examples'],\n",
        "    schema=infer_schema.outputs['output'],\n",
        "    module_file=_taxi_module_file)\n",
        "context.run(transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9",
        "colab_type": "text"
      },
      "source": [
        "### Trainer\n",
        "`Trainer` trains your custom model using TF-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429-vvCWibO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uses user-provided Python function that implements a model using TF-Learn.\n",
        "trainer = Trainer(\n",
        "    module_file=_taxi_module_file,\n",
        "    transformed_examples=transform.outputs['transformed_examples'],\n",
        "    schema=infer_schema.outputs['output'],\n",
        "    transform_output=transform.outputs['transform_output'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
        "context.run(trainer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluator (using Tensorflow Model Analysis)\n",
        "The `Evaluator` computes evaluation statistics over features of your model using [Tensorflow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started). In this section, we run TFMA in our TFX pipeline and then visualize the results to analyze the performance of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGcid3lXJsBf",
        "colab_type": "text"
      },
      "source": [
        "#### Run TFMA using the Evaluator component\n",
        "\n",
        "Here, we first define slicing specs for analyzing our data. Next, we run TFMA using these specs to generate results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVhfzzh9PDEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An empty slice spec means the overall slice, that is, the whole dataset.\n",
        "OVERALL_SLICE_SPEC = evaluator_pb2.SingleSlicingSpec()\n",
        "\n",
        "# Data can be sliced along a feature column\n",
        "# In this case, data is sliced along feature column trip_start_hour.\n",
        "FEATURE_COLUMN_SLICE_SPEC = evaluator_pb2.SingleSlicingSpec(column_for_slicing=['trip_start_hour'])\n",
        "\n",
        "# Data can be sliced by crossing feature columns\n",
        "# In this case, slices are computed for trip_start_day x trip_start_month.\n",
        "FEATURE_COLUMN_CROSS_SPEC = evaluator_pb2.SingleSlicingSpec(column_for_slicing=['trip_start_day', 'trip_start_month'])\n",
        "\n",
        "ALL_SPECS = [\n",
        "    OVERALL_SLICE_SPEC,\n",
        "    FEATURE_COLUMN_SLICE_SPEC, \n",
        "    FEATURE_COLUMN_CROSS_SPEC,\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjcx8g6mihSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use TFMA to compute a evaluation statistics over features of a model.\n",
        "model_analyzer = Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model_exports=trainer.outputs['output'],\n",
        "    feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(\n",
        "        specs=ALL_SPECS\n",
        "    ))\n",
        "context.run(model_analyzer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2VKvr3NJwii",
        "colab_type": "text"
      },
      "source": [
        "#### Get the TFMA output result path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyis6iy0HLdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_RESULT = model_analyzer.outputs['output'].get()[0].uri"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9YNBXsQKW63",
        "colab_type": "text"
      },
      "source": [
        "#### Import TFMA and load the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SeuBh8aHZ9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdLc25OnKs0G",
        "colab_type": "text"
      },
      "source": [
        "#### Visualization: Slicing Metrics\n",
        "\n",
        "To see the slices, either use the name of the column (by setting slicing_column) or provide a tfma.slicer.SingleSliceSpec (by setting slicing_spec). If neither is provided, an overall visualization will be displayed.\n",
        "\n",
        "The default visualization is the **slice overview** when the number of slices is small. It shows the value of a metric for each slice, sorted by the another metric. It is also possible to set a threshold to filter out slices with smaller weights.\n",
        "\n",
        "This view also supports the **metrics histogram** as an alternative visualization. It is also the default view when the number of slices is large. The results will be divided into buckets and the number of slices / total weights / both can be visualized. Slices with small weights can be filtered out by setting the threshold. Further filtering can be applied by dragging the grey band. To reset the range, double click the band. Filtering can be used to remove outliers in the visualization and the metrics table below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYvXSBANHdmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(tfma_result, slicing_column='trip_start_hour')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGADc5R7Q8yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show metrics sliced by 'trip_start_day' x 'trip_start_month'.\n",
        "tfma.view.render_slicing_metrics(tfma_result,\n",
        "                                 slicing_spec=tfma.slicer.SingleSliceSpec(\n",
        "                                     columns=['trip_start_day', 'trip_start_month']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvfzTTZL_0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show overall metrics.\n",
        "tfma.view.render_slicing_metrics(tfma_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Mil-7FlF_y",
        "colab_type": "text"
      },
      "source": [
        "### ModelValidator\n",
        "`ModelValidator` performs validation of your candidate model compared to a baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXk1MA7sijCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performs quality validation of a candidate model (compared to a baseline).\n",
        "model_validator = ModelValidator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['output'])\n",
        "context.run(model_validator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj",
        "colab_type": "text"
      },
      "source": [
        "### Pusher\n",
        "`Pusher` checks whether a model has passed validation, and if so, pushes the model to a file destination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45nQ69eikc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checks whether the model passed the validation steps and pushes the model\n",
        "# to a file destination if check passed.\n",
        "pusher = Pusher(\n",
        "    model_export=trainer.outputs['output'],\n",
        "    model_blessing=model_validator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "context.run(pusher)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}